{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import necessary packages\n",
    "import pandas as pd \n",
    "import splitfolders\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the splitfolders package to split our image data into train, validation, and test sets.\n",
    "#this is now commented out so that we don't create a new folder each time we run the notebook\n",
    "\n",
    "#splitfolders.ratio(\"Data\", output=\"Data_Split\",\n",
    "#    seed=42, ratio=(.64, .16, .2), group_prefix=None, move=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create DataGenerator objects for each set with rescaling for maximum pixel value of 255\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4280 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#create a train_generator from the training directory that has been created from the split folders package\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        'Data_Split/train',\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(150, 150),\n",
    "        batch_size=4280,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary', \n",
    "        color_mode='grayscale')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 978 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#create a validation_generator from the training directory that has been created from the split folders package\n",
    "validation_generator = val_datagen.flow_from_directory('Data_Split/val',\n",
    "                                                        target_size=(150, 150),\n",
    "                                                        batch_size=978,\n",
    "                                                        class_mode='binary',\n",
    "                                                        color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1173 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#create a test_generator from the training directory that has been created from the split folders package\n",
    "test_generator = test_datagen.flow_from_directory('Data_Split/test',\n",
    "                                                  target_size=(150, 150),\n",
    "                                                  batch_size=1173,\n",
    "                                                  class_mode='binary',\n",
    "                                                  color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4280, 150, 150, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4280,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.reshape(train_data.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4280, 22500)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model.add(layers.Dense(12, activation='relu', input_shape=(22500,)))\n",
    "baseline_model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model.compile(optimizer='SGD', \n",
    "                       loss='binary_crossentropy',\n",
    "                       metrics=['accuracy', metrics.Precision(), metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 12)                270012    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 270,025\n",
      "Trainable params: 270,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4280/4280 [==============================] - 1s 144us/step - loss: 0.1680 - accuracy: 0.9460 - precision_6: 0.9578 - recall_6: 0.9721\n",
      "Epoch 2/5\n",
      "4280/4280 [==============================] - 1s 142us/step - loss: 0.1680 - accuracy: 0.9456 - precision_6: 0.9591 - recall_6: 0.9700\n",
      "Epoch 3/5\n",
      "4280/4280 [==============================] - 1s 142us/step - loss: 0.1665 - accuracy: 0.9439 - precision_6: 0.9596 - recall_6: 0.9672\n",
      "Epoch 4/5\n",
      "4280/4280 [==============================] - 1s 153us/step - loss: 0.1642 - accuracy: 0.9477 - precision_6: 0.9604 - recall_6: 0.9715\n",
      "Epoch 5/5\n",
      "4280/4280 [==============================] - 1s 176us/step - loss: 0.1617 - accuracy: 0.9467 - precision_6: 0.9600 - recall_6: 0.9706\n"
     ]
    }
   ],
   "source": [
    "baseline_fit = baseline_model.fit(train_data,\n",
    "                                  train_labels,\n",
    "                                  epochs=5,\n",
    "                                  batch_size=32,\n",
    "                                  #validation_data=validation_generator,\n",
    "                                  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensor_lecture)",
   "language": "python",
   "name": "tensor_lecture"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
